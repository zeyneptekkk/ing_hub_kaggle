{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4571b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Bulundu: customer_history.csv -> C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\\customer_history.csv\n",
      "[info] Bulundu: customers.csv -> C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\\customers.csv\n",
      "[info] Bulundu: referance_data.csv -> C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\\referance_data.csv\n",
      "[info] Bulundu: referance_data_test.csv -> C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\\referance_data_test.csv\n",
      "[info] Bulundu: sample_submission.csv -> C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\\sample_submission.csv\n",
      "‚úÖ Dosyalar y√ºklendi:\n",
      "hist: (5359609, 7) | cust: (176293, 8) | ref: (133287, 3) | test: (43006, 2)\n"
     ]
    }
   ],
   "source": [
    "# === 1) K√úT√úPHANELER ===\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === 2) DOSYA BULUCU (aynƒ± klas√∂rde ya da /mnt/data'da arar) ===\n",
    "def find_file(fname: str, search_roots=(\".\",)):\n",
    "    fname = fname.lower()\n",
    "    for root in search_roots:\n",
    "        for path in glob.iglob(os.path.join(root, \"**\", \"*\"), recursive=True):\n",
    "            if os.path.isfile(path) and os.path.basename(path).lower() == fname:\n",
    "                return os.path.abspath(path)\n",
    "    return None\n",
    "\n",
    "def resolve_path(default_path: str, fallback_name: str):\n",
    "    if os.path.exists(default_path):\n",
    "        return default_path\n",
    "    p = find_file(fallback_name, search_roots=(\".\", os.getcwd()))\n",
    "    if p: \n",
    "        print(f\"[info] Bulundu: {fallback_name} -> {p}\")\n",
    "        return p\n",
    "    raise FileNotFoundError(f\"Dosya bulunamadƒ±: {fallback_name}\")\n",
    "\n",
    "# === 3) DOSYALARI OKU ===\n",
    "PATH_HISTORY = resolve_path(\"/mnt/data/customer_history.csv\", \"customer_history.csv\")\n",
    "PATH_CUSTOMERS = resolve_path(\"/mnt/data/customers.csv\", \"customers.csv\")\n",
    "PATH_REF = resolve_path(\"/mnt/data/referance_data.csv\", \"referance_data.csv\")\n",
    "PATH_TEST = resolve_path(\"/mnt/data/referance_data_test.csv\", \"referance_data_test.csv\")\n",
    "PATH_SUB = resolve_path(\"/mnt/data/sample_submission.csv\", \"sample_submission.csv\")\n",
    "\n",
    "hist = pd.read_csv(PATH_HISTORY, parse_dates=[\"date\"], low_memory=False)\n",
    "cust = pd.read_csv(PATH_CUSTOMERS, low_memory=False)\n",
    "ref  = pd.read_csv(PATH_REF, parse_dates=[\"ref_date\"], low_memory=False)\n",
    "test = pd.read_csv(PATH_TEST, parse_dates=[\"ref_date\"], low_memory=False)\n",
    "sub  = pd.read_csv(PATH_SUB, low_memory=False)\n",
    "\n",
    "# === 4) Tƒ∞PLERƒ∞ D√úZELT ===\n",
    "for df in (hist, cust, ref, test, sub):\n",
    "    if \"cust_id\" in df.columns:\n",
    "        df[\"cust_id\"] = pd.to_numeric(df[\"cust_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "if \"churn\" in ref.columns:\n",
    "    ref[\"churn\"] = pd.to_numeric(ref[\"churn\"], errors=\"coerce\").fillna(0).astype(\"Int8\")\n",
    "\n",
    "print(\"‚úÖ Dosyalar y√ºklendi:\")\n",
    "print(\"hist:\", hist.shape, \"| cust:\", cust.shape, \"| ref:\", ref.shape, \"| test:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91b4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) √ñZELLƒ∞K √úRETME FONKSƒ∞YONLARI ===\n",
    "HIST_COLS = [\n",
    "    \"cust_id\",\"date\",\n",
    "    \"mobile_eft_all_cnt\",\"active_product_category_nbr\",\n",
    "    \"mobile_eft_all_amt\",\"cc_transaction_all_amt\",\"cc_transaction_all_cnt\"\n",
    "]\n",
    "hist = hist[[c for c in HIST_COLS if c in hist.columns]].sort_values([\"cust_id\",\"date\"]).reset_index(drop=True)\n",
    "WINDOWS = [1,3,6,12]\n",
    "BASE_NUM_COLS = [c for c in HIST_COLS if c not in [\"cust_id\",\"date\"]]\n",
    "\n",
    "def _agg_safe(s, fn):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\"); s = s[np.isfinite(s)]\n",
    "    if s.size == 0: return 0.0\n",
    "    if fn==\"sum\":  return float(s.sum())\n",
    "    if fn==\"mean\": return float(s.mean())\n",
    "    if fn==\"std\":  return float(s.std(ddof=0))\n",
    "    if fn==\"max\":  return float(s.max())\n",
    "    return 0.0\n",
    "\n",
    "def aggregate_for_one(h_cust: pd.DataFrame, ref_date: pd.Timestamp):\n",
    "    feat = {\"ref_date\": ref_date}\n",
    "    h = h_cust[h_cust[\"date\"] < ref_date]\n",
    "    if h.empty:\n",
    "        for col in BASE_NUM_COLS:\n",
    "            for w in WINDOWS:\n",
    "                feat[f\"{col}_L{w}M_sum\"]=feat[f\"{col}_L{w}M_mean\"]=feat[f\"{col}_L{w}M_std\"]=feat[f\"{col}_L{w}M_max\"]=0.0\n",
    "        feat[\"recency_days\"] = 9999\n",
    "    else:\n",
    "        feat[\"recency_days\"] = int((ref_date - h[\"date\"].max()).days)\n",
    "        for w in WINDOWS:\n",
    "            start = ref_date - pd.DateOffset(months=w)\n",
    "            hw = h[(h[\"date\"] >= start) & (h[\"date\"] < ref_date)]\n",
    "            for col in BASE_NUM_COLS:\n",
    "                feat[f\"{col}_L{w}M_sum\"]  = _agg_safe(hw[col], \"sum\")\n",
    "                feat[f\"{col}_L{w}M_mean\"] = _agg_safe(hw[col], \"mean\")\n",
    "                feat[f\"{col}_L{w}M_std\"]  = _agg_safe(hw[col], \"std\")\n",
    "                feat[f\"{col}_L{w}M_max\"]  = _agg_safe(hw[col], \"max\")\n",
    "\n",
    "    eps = 1e-6\n",
    "    for w in WINDOWS:\n",
    "        feat[f\"cc_amt_per_txn_L{w}M\"] = feat.get(f\"cc_transaction_all_amt_L{w}M_sum\",0.0)/(feat.get(f\"cc_transaction_all_cnt_L{w}M_sum\",0.0)+eps)\n",
    "        feat[f\"mobile_eft_amt_per_txn_L{w}M\"] = feat.get(f\"mobile_eft_all_amt_L{w}M_sum\",0.0)/(feat.get(f\"mobile_eft_all_cnt_L{w}M_sum\",0.0)+eps)\n",
    "\n",
    "    for short,long in [(1,3),(3,6),(6,12)]:\n",
    "        for base in [\"cc_transaction_all_amt\",\"cc_transaction_all_cnt\",\"mobile_eft_all_amt\",\"mobile_eft_all_cnt\",\"active_product_category_nbr\"]:\n",
    "            ms = feat.get(f\"{base}_L{short}M_mean\",0.0)\n",
    "            ml = feat.get(f\"{base}_L{long}M_mean\",0.0)\n",
    "            feat[f\"{base}_trend_mean_L{short}vL{long}_diff\"]  = ms-ml\n",
    "            feat[f\"{base}_trend_mean_L{short}vL{long}_ratio\"] = ms/(ml+1e-6)\n",
    "    return feat\n",
    "\n",
    "def build_features_for_keys(hist_df, keys_df, n_limit=None, progress_every=5000):\n",
    "    if n_limit is not None:\n",
    "        keys_df = keys_df.head(n_limit).copy()\n",
    "    h = hist_df\n",
    "    cache = {}\n",
    "    rows = []\n",
    "    for i, r in enumerate(keys_df.itertuples(index=False), 1):\n",
    "        cid, rd = r.cust_id, r.ref_date\n",
    "        if pd.isna(cid) or pd.isna(rd): continue\n",
    "        if cid in cache: h_cust = cache[cid]\n",
    "        else:\n",
    "            h_cust = h[h[\"cust_id\"] == cid]; cache[cid] = h_cust\n",
    "        f = aggregate_for_one(h_cust, rd); f[\"cust_id\"]=cid; rows.append(f)\n",
    "        if progress_every and (i % progress_every == 0):\n",
    "            print(f\"[features] {i}/{len(keys_df)}\")\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba490b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[features] 5000/20000\n",
      "[features] 10000/20000\n",
      "[features] 15000/20000\n",
      "[features] 20000/20000\n",
      "[train] done: 20000/133287\n",
      "[features] 5000/20000\n",
      "[features] 10000/20000\n",
      "[features] 15000/20000\n",
      "[features] 20000/20000\n",
      "[train] done: 40000/133287\n",
      "[features] 5000/20000\n",
      "[features] 10000/20000\n",
      "[features] 15000/20000\n",
      "[features] 20000/20000\n",
      "[train] done: 60000/133287\n",
      "[features] 5000/20000\n",
      "[features] 10000/20000\n",
      "[features] 15000/20000\n",
      "[features] 20000/20000\n",
      "[train] done: 80000/133287\n",
      "[features] 5000/20000\n",
      "[features] 10000/20000\n",
      "[features] 15000/20000\n",
      "[features] 20000/20000\n",
      "[train] done: 100000/133287\n",
      "[features] 5000/20000\n",
      "[features] 10000/20000\n",
      "[features] 15000/20000\n",
      "[features] 20000/20000\n",
      "[train] done: 120000/133287\n",
      "[features] 5000/13287\n",
      "[features] 10000/13287\n",
      "[train] done: 133287/133287\n"
     ]
    }
   ],
   "source": [
    "# === 3) T√úM Eƒûƒ∞Tƒ∞M VERƒ∞Sƒ∞Nƒ∞ PARTƒ∞ PARTƒ∞ √úRET ===\n",
    "BATCH = 20000\n",
    "keys = ref[[\"cust_id\",\"ref_date\",\"churn\"]].sort_values(\"ref_date\").reset_index(drop=True)\n",
    "parts = []\n",
    "for s in range(0, len(keys), BATCH):\n",
    "    e = min(s + BATCH, len(keys))\n",
    "    keys_part = keys.iloc[s:e][[\"cust_id\",\"ref_date\"]]\n",
    "    feats_part = build_features_for_keys(hist, keys_part, n_limit=None)\n",
    "    part = keys.iloc[s:e].merge(feats_part, on=[\"cust_id\",\"ref_date\"], how=\"left\").merge(cust, on=\"cust_id\", how=\"left\")\n",
    "    parts.append(part)\n",
    "    print(f\"[train] done: {e}/{len(keys)}\")\n",
    "X_full = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# eksik doldur\n",
    "num_cols = X_full.select_dtypes(include=\"number\").columns\n",
    "cat_cols = [c for c in X_full.columns if c not in num_cols and c != \"ref_date\"]\n",
    "X_full[num_cols] = X_full[num_cols].fillna(0)\n",
    "for c in cat_cols: X_full[c] = X_full[c].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8634c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f46bb99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 15178, number of negative: 88713\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21950\n",
      "[LightGBM] [Info] Number of data points in the train set: 103891, number of used features: 144\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.703013\tvalid_0's binary_logloss: 0.676788\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.702374\tvalid_0's binary_logloss: 0.673293\n",
      "{'Gini': 0.4047, 'Recall@10%': 0.2067, 'Lift@10%': 2.0663, 'CompetitionScore': 0.8438}\n",
      "‚úÖ LightGBM modeli eƒüitildi ve TRAIN_FEATS kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# === 4) MODEL: LIGHTGBM (g√ºncel ve hatasƒ±z s√ºr√ºm) ===\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "TARGET = \"churn\"\n",
    "PROTECTED = [\"cust_id\",\"ref_date\",TARGET]\n",
    "\n",
    "# 1Ô∏è‚É£ Encode i≈ülemi (kategorikleri sayƒ±ya √ßevir)\n",
    "X_full_enc = pd.get_dummies(\n",
    "    X_full, \n",
    "    columns=[c for c in X_full.columns if (X_full[c].dtype==\"object\" and c not in PROTECTED)],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# 2Ô∏è‚É£ Zamansal b√∂lme (%80 train, %20 validation)\n",
    "cut = X_full_enc[\"ref_date\"].quantile(0.80)\n",
    "train_mask = X_full_enc[\"ref_date\"] < cut\n",
    "valid_mask = ~train_mask\n",
    "\n",
    "y_train = X_full_enc.loc[train_mask, TARGET].astype(int).values\n",
    "y_valid = X_full_enc.loc[valid_mask, TARGET].astype(int).values\n",
    "feat_cols = [c for c in X_full_enc.columns if c not in PROTECTED]\n",
    "X_train = X_full_enc.loc[train_mask, feat_cols].fillna(0)\n",
    "X_valid = X_full_enc.loc[valid_mask,  feat_cols].fillna(0)\n",
    "\n",
    "# 3Ô∏è‚É£ Model tanƒ±mƒ±\n",
    "clf = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Eƒüitim (yeni LightGBM s√ºr√ºm√ºne uygun callbacks yapƒ±sƒ±)\n",
    "clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric=\"auc\",\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=50),\n",
    "        log_evaluation(period=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5Ô∏è‚É£ Tahmin ve metrikler\n",
    "valid_proba = clf.predict_proba(X_valid)[:,1]\n",
    "\n",
    "def gini_from_auc(y_true, y_score):\n",
    "    return 2 * roc_auc_score(y_true, y_score) - 1\n",
    "\n",
    "def recall_at_k(y_true, y_score, k=0.10):\n",
    "    n = len(y_true)\n",
    "    topk = int(np.ceil(n * k))\n",
    "    idx = np.argsort(-y_score)[:topk]\n",
    "    return float(y_true[idx].sum()) / float(y_true.sum() + 1e-9)\n",
    "\n",
    "def lift_at_k(y_true, y_score, k=0.10):\n",
    "    n = len(y_true)\n",
    "    topk = int(np.ceil(n * k))\n",
    "    idx = np.argsort(-y_score)[:topk]\n",
    "    prec = float(y_true[idx].mean())\n",
    "    prev = float(y_true.mean())\n",
    "    return prec / max(prev, 1e-9)\n",
    "\n",
    "gini  = gini_from_auc(y_valid, valid_proba)\n",
    "rec10 = recall_at_k(y_valid, valid_proba, 0.10)\n",
    "lift10= lift_at_k(y_valid, valid_proba, 0.10)\n",
    "score = 0.4*gini + 0.3*rec10 + 0.3*lift10\n",
    "\n",
    "print({\n",
    "    \"Gini\": round(gini, 4),\n",
    "    \"Recall@10%\": round(rec10, 4),\n",
    "    \"Lift@10%\": round(lift10, 4),\n",
    "    \"CompetitionScore\": round(score, 4)\n",
    "})\n",
    "\n",
    "# 6Ô∏è‚É£ Eƒüitimdeki kolonlarƒ± test pipeline‚Äôda hizalamak i√ßin kaydet\n",
    "TRAIN_FEATS = X_train.columns.tolist()\n",
    "print(\"‚úÖ LightGBM modeli eƒüitildi ve TRAIN_FEATS kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7cd3356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "customers.csv\n",
      "customer_history.csv\n",
      "LightGBM.ipynb\n",
      "referance_data.csv\n",
      "referance_data_test.csv\n",
      "sample_submission.csv\n",
      "started.ipynb\n",
      "submission.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\"\n",
    "\n",
    "for f in os.listdir(BASE_DIR):\n",
    "    print(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a7a9296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[features] 5000/43006\n",
      "[features] 10000/43006\n",
      "[features] 15000/43006\n",
      "[features] 20000/43006\n",
      "[features] 25000/43006\n",
      "[features] 30000/43006\n",
      "[features] 35000/43006\n",
      "[features] 40000/43006\n",
      "‚úÖ submission.csv olu≈üturuldu! Satƒ±r sayƒ±sƒ±: (43006, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.482841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.499260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.619356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.594264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.452892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id     churn\n",
       "0        1  0.482841\n",
       "1        2  0.499260\n",
       "2        9  0.619356\n",
       "3       15  0.594264\n",
       "4       19  0.452892"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 5) TEST √ñZELLƒ∞KLERƒ∞ VE SUBMISSION ===\n",
    "test_keys = test[[\"cust_id\",\"ref_date\"]].copy()\n",
    "X_hist_test = build_features_for_keys(hist, test_keys, n_limit=None, progress_every=5000)\n",
    "\n",
    "X_test = test_keys.merge(X_hist_test, on=[\"cust_id\",\"ref_date\"], how=\"left\").merge(cust, on=\"cust_id\", how=\"left\")\n",
    "num_cols = X_test.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X_test.columns if c not in num_cols and c not in [\"ref_date\"]]\n",
    "X_test[num_cols] = X_test[num_cols].fillna(0)\n",
    "for c in cat_cols: X_test[c] = X_test[c].fillna(\"Unknown\")\n",
    "\n",
    "X_test_enc = pd.get_dummies(X_test, columns=cat_cols, drop_first=True)\n",
    "X_test_enc = X_test_enc.reindex(columns=TRAIN_FEATS, fill_value=0)\n",
    "\n",
    "test_proba = clf.predict_proba(X_test_enc)[:, 1]\n",
    "out = sub[[\"cust_id\"]].merge(pd.DataFrame({\"cust_id\": X_test[\"cust_id\"], \"churn\": test_proba}), on=\"cust_id\", how=\"left\")\n",
    "out[\"churn\"] = out[\"churn\"].fillna(float(ref[\"churn\"].mean()))\n",
    "out.to_csv(\"submission.csv\", index=False, float_format=\"%.6f\")\n",
    "print(\"‚úÖ submission.csv olu≈üturuldu! Satƒ±r sayƒ±sƒ±:\", out.shape)\n",
    "out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2346123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4d86d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ CatBoost kurulumu ba≈ülatƒ±lƒ±yor...\n",
      "[info] Bulundu: customer_history.csv -> C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\\customer_history.csv\n",
      "[info] Bulundu: customers.csv -> C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\\customers.csv\n",
      "[info] Bulundu: referance_data.csv -> C:\\Users\\hp\\OneDrive\\Masa√ºst√º\\ing-hubs-turkiye-datathon\\referance_data.csv\n",
      "‚úÖ Dosyalar y√ºklendi: \n",
      "  hist: (5359609, 7) | cust: (176293, 8) | ref: (133287, 3)\n",
      "üéØ MINI | keys: 12000\n",
      "[features] 2000/12000\n",
      "[features] 4000/12000\n",
      "[features] 6000/12000\n",
      "[features] 8000/12000\n",
      "[features] 10000/12000\n",
      "[features] 12000/12000\n",
      "‚úÖ Eƒüitim seti: (12000, 20) | Train: (8706, 50) | Valid: (3294, 50)\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1208, number of negative: 7498\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1701\n",
      "[LightGBM] [Info] Number of data points in the train set: 8706, number of used features: 47\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138755 -> initscore=-1.825670\n",
      "[LightGBM] [Info] Start training from score -1.825670\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's auc: 0.530744\tvalid_0's binary_logloss: 0.412342\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.522982\tvalid_0's binary_logloss: 0.38942\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1208, number of negative: 7498\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1701\n",
      "[LightGBM] [Info] Number of data points in the train set: 8706, number of used features: 47\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138755 -> initscore=-1.825670\n",
      "[LightGBM] [Info] Start training from score -1.825670\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's auc: 0.528484\tvalid_0's binary_logloss: 0.416235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.540698\tvalid_0's binary_logloss: 0.389403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1208, number of negative: 7498\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1701\n",
      "[LightGBM] [Info] Number of data points in the train set: 8706, number of used features: 47\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138755 -> initscore=-1.825670\n",
      "[LightGBM] [Info] Start training from score -1.825670\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's auc: 0.52176\tvalid_0's binary_logloss: 0.412664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.497369\tvalid_0's binary_logloss: 0.389595\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1208, number of negative: 7498\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1701\n",
      "[LightGBM] [Info] Number of data points in the train set: 8706, number of used features: 47\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138755 -> initscore=-1.825670\n",
      "[LightGBM] [Info] Start training from score -1.825670\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's auc: 0.528673\tvalid_0's binary_logloss: 0.414569\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.498442\tvalid_0's binary_logloss: 0.38954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1208, number of negative: 7498\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1701\n",
      "[LightGBM] [Info] Number of data points in the train set: 8706, number of used features: 47\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138755 -> initscore=-1.825670\n",
      "[LightGBM] [Info] Start training from score -1.825670\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's auc: 0.525223\tvalid_0's binary_logloss: 0.413838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.497369\tvalid_0's binary_logloss: 0.389595\n",
      "\n",
      "üìä VALIDATION SONU√áLARI (LGBM+CatBoost Ensemble): {'Gini': 0.1065, 'Recall@10%': 0.1386, 'Lift@10%': 1.3832, 'CompetitionScore': 0.4991}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üß† ING Datathon ‚Äî MINI (LGBM + CatBoost Regularized Ensemble)\n",
    "# ============================================================\n",
    "\n",
    "# === 0) Kurulum (CatBoost y√ºkl√º deƒüilse) ===\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "except ModuleNotFoundError:\n",
    "    print(\"üì¶ CatBoost kurulumu ba≈ülatƒ±lƒ±yor...\")\n",
    "    !pip install catboost -q\n",
    "    from catboost import CatBoostClassifier\n",
    "\n",
    "# === 1) K√ºt√ºphaneler ===\n",
    "import os, glob, warnings, gc\n",
    "import pandas as pd, numpy as np\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 240)\n",
    "\n",
    "# === 2) Sabitler ===\n",
    "SAMPLE_N       = 12000\n",
    "FOCUS_RECENT   = True\n",
    "RECENT_FRAC    = 0.6\n",
    "SEED           = 42\n",
    "ENSEMBLE_SEEDS = [42, 87, 123, 2025, 7]\n",
    "\n",
    "# === 3) Dosya bulucu ===\n",
    "def find_file(fname: str, search_roots=(\".\",)):\n",
    "    fname = fname.lower()\n",
    "    for root in search_roots:\n",
    "        for path in glob.iglob(os.path.join(root, \"**\", \"*\"), recursive=True):\n",
    "            if os.path.isfile(path) and os.path.basename(path).lower() == fname:\n",
    "                return os.path.abspath(path)\n",
    "    return None\n",
    "\n",
    "def resolve_path(default_path: str, fallback_name: str):\n",
    "    if os.path.exists(default_path): return default_path\n",
    "    p = find_file(fallback_name, search_roots=(\".\", os.getcwd()))\n",
    "    if p:\n",
    "        print(f\"[info] Bulundu: {fallback_name} -> {p}\")\n",
    "        return p\n",
    "    raise FileNotFoundError(f\"Dosya bulunamadƒ±: {fallback_name}\")\n",
    "\n",
    "PATH_HISTORY   = resolve_path(\"/mnt/data/customer_history.csv\", \"customer_history.csv\")\n",
    "PATH_CUSTOMERS = resolve_path(\"/mnt/data/customers.csv\", \"customers.csv\")\n",
    "PATH_REF       = resolve_path(\"/mnt/data/referance_data.csv\", \"referance_data.csv\")\n",
    "\n",
    "hist = pd.read_csv(PATH_HISTORY, parse_dates=[\"date\"], low_memory=False)\n",
    "cust = pd.read_csv(PATH_CUSTOMERS, low_memory=False)\n",
    "ref  = pd.read_csv(PATH_REF, parse_dates=[\"ref_date\"], low_memory=False)\n",
    "\n",
    "for df in (hist, cust, ref):\n",
    "    if \"cust_id\" in df.columns:\n",
    "        df[\"cust_id\"] = pd.to_numeric(df[\"cust_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "if \"churn\" in ref.columns:\n",
    "    ref[\"churn\"] = pd.to_numeric(ref[\"churn\"], errors=\"coerce\").fillna(0).astype(\"Int8\")\n",
    "cust.columns = cust.columns.str.strip()\n",
    "hist.columns = hist.columns.str.strip()\n",
    "\n",
    "print(\"‚úÖ Dosyalar y√ºklendi:\",\n",
    "      \"\\n  hist:\", hist.shape,\n",
    "      \"| cust:\", cust.shape,\n",
    "      \"| ref:\", ref.shape)\n",
    "\n",
    "# === 4) Metrikler ===\n",
    "def gini_from_auc(y_true, y_score): return 2*roc_auc_score(y_true, y_score)-1\n",
    "def recall_at_k(y_true, y_score, k=0.10):\n",
    "    y_true = np.array(y_true); topk = int(np.ceil(len(y_true)*k))\n",
    "    idx = np.argsort(-y_score)[:topk]; return float(y_true[idx].sum())/float(y_true.sum()+1e-9)\n",
    "def lift_at_k(y_true, y_score, k=0.10):\n",
    "    y_true = np.array(y_true); topk = int(np.ceil(len(y_true)*k))\n",
    "    idx = np.argsort(-y_score)[:topk]; prec = float(y_true[idx].mean()); prev = float(y_true.mean())\n",
    "    return prec / max(prev, 1e-9)\n",
    "def competition_score(y_true, y_score):\n",
    "    g=gini_from_auc(y_true,y_score); r=recall_at_k(y_true,y_score); l=lift_at_k(y_true,y_score)\n",
    "    s=0.4*g+0.3*r+0.3*l; return {\"Gini\":round(g,4),\"Recall@10%\":round(r,4),\"Lift@10%\":round(l,4),\"CompetitionScore\":round(s,4)}\n",
    "\n",
    "# === 5) Key se√ßimi (mini √∂rneklem) ===\n",
    "def pick_keys_for_mini(ref_df, sample_n=SAMPLE_N, focus_recent=FOCUS_RECENT, recent_frac=RECENT_FRAC, seed=SEED):\n",
    "    keys = ref_df[[\"cust_id\",\"ref_date\",\"churn\"]].copy().sort_values(\"ref_date\").reset_index(drop=True)\n",
    "    if focus_recent:\n",
    "        q = keys[\"ref_date\"].quantile(1.0 - recent_frac)\n",
    "        keys = keys[keys[\"ref_date\"] >= q].reset_index(drop=True)\n",
    "    if len(keys) <= sample_n: return keys\n",
    "    keys[\"ref_month\"] = keys[\"ref_date\"].dt.to_period(\"M\")\n",
    "    month_sizes = keys[\"ref_month\"].value_counts().sort_index()\n",
    "    month_target = (month_sizes / month_sizes.sum() * sample_n).round().astype(int)\n",
    "    samples=[]\n",
    "    for m,n_target in month_target.items():\n",
    "        km=keys[keys[\"ref_month\"]==m]\n",
    "        if n_target<=0 or km.empty: continue\n",
    "        pos=km[km[\"churn\"]==1]; neg=km[km[\"churn\"]==0]\n",
    "        pos_ratio=len(pos)/max(len(km),1)\n",
    "        n_pos=int(round(n_target*pos_ratio)); n_neg=max(n_target-n_pos,0)\n",
    "        take_pos=pos.sample(n=min(n_pos,len(pos)),random_state=seed) if len(pos) else pos\n",
    "        take_neg=neg.sample(n=min(n_neg,len(neg)),random_state=seed) if len(neg) else neg\n",
    "        pack=pd.concat([take_pos,take_neg],axis=0)\n",
    "        if len(pack)<n_target and len(km)>len(pack):\n",
    "            extra=km.drop(pack.index).sample(n=min(n_target-len(pack),len(km)-len(pack)),random_state=seed)\n",
    "            pack=pd.concat([pack,extra],axis=0)\n",
    "        samples.append(pack)\n",
    "    keys=pd.concat(samples,axis=0).sample(frac=1.0,random_state=seed)\n",
    "    return keys.drop(columns=[\"ref_month\"]).reset_index(drop=True)\n",
    "\n",
    "# === 6) Basit Feature Builder ===\n",
    "def aggregate_for_one(h_cust, ref_date):\n",
    "    feat={\"ref_date\":ref_date}\n",
    "    h=h_cust[h_cust[\"date\"]<ref_date]\n",
    "    feat[\"txn_sum\"]=h[\"cc_transaction_all_amt\"].sum() if \"cc_transaction_all_amt\" in h else 0\n",
    "    feat[\"eft_sum\"]=h[\"mobile_eft_all_amt\"].sum() if \"mobile_eft_all_amt\" in h else 0\n",
    "    feat[\"txn_cnt\"]=h[\"cc_transaction_all_cnt\"].sum() if \"cc_transaction_all_cnt\" in h else 0\n",
    "    feat[\"eft_cnt\"]=h[\"mobile_eft_all_cnt\"].sum() if \"mobile_eft_all_cnt\" in h else 0\n",
    "    feat[\"recency_days\"]=int((ref_date - h[\"date\"].max()).days) if not h.empty else 9999\n",
    "    feat[\"cc_to_eft_ratio\"]=(feat[\"txn_sum\"]+1)/(feat[\"eft_sum\"]+1)\n",
    "    return feat\n",
    "\n",
    "def build_features_for_keys(hist_df, keys_df, progress_every=2000):\n",
    "    rows, cache=[],{}\n",
    "    for i,r in enumerate(keys_df.itertuples(index=False),1):\n",
    "        cid,rd=r.cust_id,r.ref_date\n",
    "        if pd.isna(cid) or pd.isna(rd): continue\n",
    "        h_cust=cache.get(cid) or hist_df[hist_df[\"cust_id\"]==cid]\n",
    "        cache[cid]=h_cust\n",
    "        f=aggregate_for_one(h_cust,rd); f[\"cust_id\"]=cid; rows.append(f)\n",
    "        if i%progress_every==0: print(f\"[features] {i}/{len(keys_df)}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# === 7) Calendar features ===\n",
    "def add_calendar_feats(df):\n",
    "    df[\"ref_month\"]=df[\"ref_date\"].dt.month.astype(int)\n",
    "    df[\"ref_quarter\"]=df[\"ref_date\"].dt.quarter.astype(int)\n",
    "    df[\"ref_month_sin\"]=np.sin(2*np.pi*df[\"ref_month\"]/12.0)\n",
    "    df[\"ref_month_cos\"]=np.cos(2*np.pi*df[\"ref_month\"]/12.0)\n",
    "    return df\n",
    "\n",
    "# === 8) Encoding ===\n",
    "def encode_categoricals(X):\n",
    "    X=X.copy()\n",
    "    cat_cols=X.select_dtypes(exclude=\"number\").columns\n",
    "    for c in cat_cols:\n",
    "        X[c]=X[c].astype(str)\n",
    "    return pd.get_dummies(X,drop_first=True)\n",
    "\n",
    "# === 9) Eƒüitim & Ensemble ===\n",
    "def train_eval_mini():\n",
    "    keys = pick_keys_for_mini(ref, SAMPLE_N, FOCUS_RECENT, RECENT_FRAC, SEED)\n",
    "    print(f\"üéØ MINI | keys: {len(keys)}\")\n",
    "\n",
    "    feats = build_features_for_keys(hist, keys[[\"cust_id\",\"ref_date\"]], progress_every=2000)\n",
    "    X_full = keys.merge(feats,on=[\"cust_id\",\"ref_date\"],how=\"left\").merge(cust,on=\"cust_id\",how=\"left\")\n",
    "    X_full = add_calendar_feats(X_full)\n",
    "    X_full_enc = encode_categoricals(X_full)\n",
    "\n",
    "    cut = X_full[\"ref_date\"].quantile(0.8)\n",
    "    train_mask = X_full[\"ref_date\"] < cut\n",
    "    valid_mask = ~train_mask\n",
    "    TARGET = \"churn\"\n",
    "    feat_cols = [c for c in X_full_enc.columns if c not in [\"cust_id\", TARGET, \"ref_date\"]]\n",
    "\n",
    "    X_train, y_train = X_full_enc.loc[train_mask, feat_cols], X_full.loc[train_mask, TARGET]\n",
    "    X_valid, y_valid = X_full_enc.loc[valid_mask, feat_cols], X_full.loc[valid_mask, TARGET]\n",
    "\n",
    "    print(\"‚úÖ Eƒüitim seti:\", X_full.shape, \"| Train:\", X_train.shape, \"| Valid:\", X_valid.shape)\n",
    "\n",
    "    neg, pos = (y_train==0).sum(), (y_train==1).sum()\n",
    "    scale_pos = float(np.sqrt((neg+1e-9)/(pos+1e-9)))\n",
    "\n",
    "    params_lgbm = dict(\n",
    "        objective=\"binary\",\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=6,\n",
    "        num_leaves=48,\n",
    "        subsample=0.75,\n",
    "        colsample_bytree=0.7,\n",
    "        min_child_samples=100,\n",
    "        reg_alpha=0.3,\n",
    "        reg_lambda=1.5,\n",
    "        scale_pos_weight=scale_pos,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    params_cat = dict(\n",
    "        iterations=1200,\n",
    "        learning_rate=0.04,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=5,\n",
    "        subsample=0.8,\n",
    "        random_strength=1.5,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        early_stopping_rounds=80,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    valid_probas_lgb, valid_probas_cat = [], []\n",
    "\n",
    "    for seed in ENSEMBLE_SEEDS:\n",
    "        clf_lgb = LGBMClassifier(random_state=seed, **params_lgbm)\n",
    "        clf_lgb.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            eval_metric=['auc'],\n",
    "            callbacks=[early_stopping(stopping_rounds=80), log_evaluation(period=50)]\n",
    "        )\n",
    "        valid_probas_lgb.append(clf_lgb.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "        clf_cat = CatBoostClassifier(random_seed=seed, **params_cat)\n",
    "        clf_cat.fit(X_train, y_train, eval_set=(X_valid, y_valid))\n",
    "        valid_probas_cat.append(clf_cat.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "    p_lgb = np.mean(valid_probas_lgb, axis=0)\n",
    "    p_cat = np.mean(valid_probas_cat, axis=0)\n",
    "    valid_proba = 0.6*p_lgb + 0.4*p_cat  # aƒüƒ±rlƒ±klƒ± ensemble\n",
    "\n",
    "    metrics = competition_score(y_valid, valid_proba)\n",
    "    print(\"\\nüìä VALIDATION SONU√áLARI (LGBM+CatBoost Ensemble):\", metrics)\n",
    "    return metrics\n",
    "\n",
    "# === 10) √áalƒ±≈ütƒ±r ===\n",
    "if __name__ == \"__main__\":\n",
    "    _ = train_eval_mini()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0caec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc1a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93473d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
